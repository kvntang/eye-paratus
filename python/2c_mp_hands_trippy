import cv2
import mediapipe as mp
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles
mp_hands = mp.solutions.hands
import numpy as np
import time

# For webcam input:
cap = cv2.VideoCapture(0)

success, image = cap.read()
if not success:
    print("Ignoring empty camera frame.")
    # If loading a video, use 'break' instead of 'continue'.
    cap.release()
    exit()

height, width = image.shape[:2]
x_scale_factor = 1.62  # Modify this for different sizes
y_scale_factor = 2.15 
new_width = int(width * x_scale_factor)
new_height = int(height * y_scale_factor)

y_translation = -33  # Change this value as needed
translation_matrix = np.float32([[1, 0, 0], [0, 1, y_translation]])
# x_translation = 50
# translation_matrix = np.float32([[1, 0, x_translation], [0, 1, 0]])

desired_frame_rate = 30  # For example, 30 FPS
cap.set(cv2.CAP_PROP_FPS, desired_frame_rate)

# Create a window
cv2.namedWindow("Camera Feed", cv2.WND_PROP_FULLSCREEN)

# Set window to fullscreen
cv2.setWindowProperty("Camera Feed", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)

prev_time = time.time();

with mp_hands.Hands(
    model_complexity=0,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5) as hands:
    pos = None

    while cap.isOpened():
        success, image = cap.read()

        if not success:
            print("Ignoring empty camera frame.")
            # If loading a video, use 'break' instead of 'continue'.
            continue

        # To improve performance, optionally mark the image as not writeable to
        # pass by reference.
        image.flags.writeable = False
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = hands.process(image)

        # Draw the hand annotations on the image.
        image.flags.writeable = True
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        # black out here
        image = np.zeros(image.shape, np.uint8)

        # Draw just the thumb and print position
        lmList = []
        if results.multi_hand_landmarks:
            myhand = results.multi_hand_landmarks[0]
            for id, lm in enumerate(myhand.landmark):
                h, w, c = image.shape
                cx, cy = int(lm.x * w), int(lm.y*h)
                lmList.append([id, cx, cy])
            if len(lmList) != 0:
                pos = lmList[8] #show only one landmark
                # cv2.circle(image, (pos[1], pos[2]), 15, (0, 255, 0), cv2.FILLED)
                text = f'{str(pos[1])}, {str(pos[2])} '
                cv2.putText(image, text, (10, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 0), 3)
                # draw line between point and center of screen
                # cv2.line(image, (pos[1], pos[2]), (300, 225), (0, 255, 0), thickness=2, lineType=8)
        
        try:
            cv2.circle(image, (pos[1], pos[2]), 15, (0, 255, 0), cv2.FILLED)   
        except:
            print("No hand detected")
        
        #   #draw all landmarks
        #   for hand_landmarks in results.multi_hand_landmarks:
        #     mp_drawing.draw_landmarks(
        #         image,
        #         hand_landmarks,
        #         mp_hands.HAND_CONNECTIONS,
        #         mp_drawing_styles.get_default_hand_landmarks_style(),
        #         mp_drawing_styles.get_default_hand_connections_style())
            
        # Flip the image horizontally for a selfie-view display.
        # cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))
        
        resized_frame = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)

        x_center = new_width // 2
        y_center = new_height // 2

        startx = x_center - (width // 2)
        starty = y_center - (height // 2)
        cropped_frame = resized_frame[starty:starty+height, startx:startx+width]
        
        translated_frame = cv2.warpAffine(cropped_frame, translation_matrix, (cropped_frame.shape[1], cropped_frame.shape[0]))

        # cv2.imshow("Camera Feed", cropped_frame)
        cv2.imshow("Camera Feed", translated_frame)
        # cv2.imshow("Camera Feed", image)

        # This prints framerate
        now_time = time.time()
        elapsed = prev_time - now_time
        print("Framerate: ", abs(1/elapsed))
        prev_time = now_time

        if cv2.waitKey(5) & 0xFF == 27:
            break

cap.release()
cv2.destroyAllWindows